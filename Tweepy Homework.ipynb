{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import tweepy\n",
    "import time\n",
    "import seaborn as sns\n",
    "\n",
    "# Twitter API Keys\n",
    "consumer_key = \"0YMgehLA0fffLLU8ymwXCI93J\"\n",
    "consumer_secret = \"mBflJdnU6MIK46oul0DXTAnaAv8Bw9TvqDmF8PBtjn6Stm6D3d\"\n",
    "access_token = \"937016914504663040-MDEJRJnYOIPdjB10kHP2faSlfQ3AzwK\"\n",
    "access_token_secret = \"CWs0MS4EJHGOmXKHYGcAuPmqEohcDrxiexKoSDoxEtKIM\"\n",
    "\n",
    "# Setup Tweepy API Authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Target User Account\n",
    "target_user = (\"@BBC\", \"@CBS\", \"@CNN\", \"@Fox\", \"@nytimes\")\n",
    "\n",
    "\n",
    "# Import and Initialize Sentiment Analyzer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "sentiments = []\n",
    "\n",
    "for target in target_user:\n",
    "    \n",
    "    # Variables for holding sentiments\n",
    "    counter = 1\n",
    "    #compound_list = []    \n",
    "    #positive_list = []\n",
    "    #negative_list = []\n",
    "    #neutral_list = []\n",
    "\n",
    "\n",
    "# Loop through 5 pages of tweets (total 100 tweets)\n",
    "    for x in range(5):\n",
    "\n",
    "        # Get all tweets from home feed\n",
    "        tweets = api.user_timeline(target, page = x+1)\n",
    "\n",
    "        # Loop through all tweets\n",
    "        for tweet in tweets:\n",
    "           \n",
    "            # Run Vader Analysis on each tweet\n",
    "            compound = analyzer.polarity_scores(tweet[\"text\"])[\"compound\"]\n",
    "            pos = analyzer.polarity_scores(tweet[\"text\"])[\"pos\"]\n",
    "            neu = analyzer.polarity_scores(tweet[\"text\"])[\"neu\"]\n",
    "            neg = analyzer.polarity_scores(tweet[\"text\"])[\"neg\"]\n",
    "\n",
    "            # Add sentiments for each tweet into an array\n",
    "            sentiments.append({\"User\": target, \n",
    "                               \"Date\": tweet[\"created_at\"], \n",
    "                               \"Tweet\": tweet[\"text\"],\n",
    "                               \"Compound\": compound,\n",
    "                               \"Positive\": pos,\n",
    "                               \"Negative\": neu,\n",
    "                               \"Neutral\": neg,\n",
    "                               \"Tweets Ago\": counter})\n",
    "\n",
    "            counter = counter + 1\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert sentiments to DataFrame\n",
    "sentiments_pd = pd.DataFrame.from_dict(sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments_pd.head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot\n",
    "sns.lmplot(x = \"Tweets Ago\", y = \"Compound\", data = sentiments_pd, fit_reg = False, hue = \"User\", legend = True)\n",
    "sns.set_style(\"dark\")\n",
    "# Incorporate the other graph properties\n",
    "plt.title(\"Sentiment Analysis of Tweets (%s) for %s\" % (time.strftime(\"%x\"), target_user))\n",
    "plt.ylabel(\"Tweet Polarity\")\n",
    "plt.xlabel(\"Tweets Ago\")\n",
    "plt.grid()\n",
    "plt.savefig(\"scatter_plot.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compound_avg = pd.DataFrame(sentiments_pd.groupby(\"User\").mean()[\"Compound\"], index = None).reset_index()\n",
    "\n",
    "sns.barplot(x = \"User\", y = \"Compound\", data = sentiments_pd, ci = 0)\n",
    "plt.title(\"Average Sentiment Analysis of Tweets (%s) for %s\" % (time.strftime(\"%x\"), target_user))\n",
    "plt.savefig(\"bar_plot.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compound_avg)\n",
    "print(\"The overall average sentiment score for the last 100 tweets, for each news source, is: %s\" % round(sentiments_pd[\"Compound\"].mean(),6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentiments_pd.to_csv(\"sentiments.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3 Observations\n",
    "\n",
    "#1. CBS has the greatest compund score meaning that they mostly tweet out positively.\n",
    "#2. CNN sends out more negative tweets than the other news agencies.\n",
    "#3. Out of the five news sources CBS has the least negative comments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
